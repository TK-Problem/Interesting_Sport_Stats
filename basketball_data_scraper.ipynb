{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Import packages\n",
    "Oddsportal has dynamic content, i.e. javascript rendered page. I used `selenium` package to load and render url content with Morzilla Firefox then parsed source code to `BeautifulSoup` to extract information of interest."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "from selenium import webdriver\n",
    "from selenium.webdriver.common.by import By\n",
    "from selenium.webdriver.common.keys import Keys\n",
    "from selenium.webdriver.support.ui import WebDriverWait\n",
    "from selenium.webdriver.support import expected_conditions as EC\n",
    "from selenium.webdriver.common.action_chains import ActionChains\n",
    "import bs4\n",
    "import time\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from datetime import datetime\n",
    "from psw import psw, usr"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Helper functions for processing HTML code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_unique_href(soup, league, season):\n",
    "    \"\"\"\n",
    "    Input:\n",
    "        soup: bs4.BeautifulSoup element (HTML source code parced with selenium webdriver)\n",
    "        league: string, e.g. NBA or Euro\n",
    "        season: string  e.g. 2017/1018 or 2013/2014\n",
    "    Output:\n",
    "        List of list. Each list element contains a size of 3\n",
    "        [league, season, url (unique for each game)]\n",
    "    \"\"\"\n",
    "    _data = list()\n",
    "    rows = soup.tbody.findAll('tr')\n",
    "    for row in rows:\n",
    "        if len(row.contents) == 6:\n",
    "            # read url for detailed match coefficient analysis\n",
    "            href = row.contents[1].find('a', href=True)\n",
    "            href = \"https://www.oddsportal.com\" + href['href']\n",
    "            \n",
    "            _data.append([league, season, href])\n",
    "    return _data\n",
    "\n",
    "def convert_2_int(string):\n",
    "    \"\"\"\n",
    "    Input:\n",
    "        string: e.g. \"123\" or \"93\"\n",
    "    Output:\n",
    "        int:\n",
    "    If ValueError, print problematic string and return NAN value\n",
    "    \"\"\"\n",
    "    try:\n",
    "        return int(string)\n",
    "    except ValueError:\n",
    "        print(\"Input {} could not be converted to integer\".format(string))\n",
    "        return np.nan\n",
    "    \n",
    "def convert_2_float(string):\n",
    "    \"\"\"\n",
    "    Input:\n",
    "        string: e.g. \"123\" or \"93\"\n",
    "    Output:\n",
    "        int:\n",
    "    If ValueError, print problematic string and return NAN value\n",
    "    \"\"\"\n",
    "    try:\n",
    "        return float(string)\n",
    "    except ValueError:\n",
    "        print(\"Input {} could not be converted to float\".format(string))\n",
    "        return np.nan"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Initiate webdriver\n",
    "`executable_path` points to excecutable used to connect to Firefox. To use different browser download approprate geckodriver (hyperlink) or refer to this Stack exchange post."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 9.85 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "driver = webdriver.Firefox(executable_path=r\"geckodriver.exe\")\n",
    "\n",
    "# go to Oddsportal website\n",
    "driver.get(\"https://www.oddsportal.com\")\n",
    "\n",
    "# click on log-in button\n",
    "driver.find_element_by_tag_name('button').click()\n",
    "\n",
    "# enter User name and psw\n",
    "driver.find_element_by_id('login-username1').send_keys(usr)\n",
    "driver.find_element_by_id('login-password1').send_keys(psw, Keys.ENTER)\n",
    "\n",
    "# set timeout for page loadding to 30 sec\n",
    "driver.set_page_load_timeout(30)\n",
    "\n",
    "# set wait element for explicit wait\n",
    "wait = WebDriverWait(driver, 10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load NBA and Euroleague 2013-2018 season data\n",
    "* `season_dict` dictonary keys are  league and season names, while values are tuples (url, number of pages to iterate over).\n",
    "* itrate over season url pages and read team scored points and home/away team average coefficients\n",
    "* transform data into pandas DataFrame and save it as .csv file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "league = \"Euroleague\"\n",
    "season = \"2017_2018\"\n",
    "season_url = \"https://www.oddsportal.com/basketball/europe/euroleague-2017-2018/results/#/page/\"\n",
    "# number of pages for the season\n",
    "no_pages = 6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 5.7 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "# temporary list to store data\n",
    "_data = list()\n",
    "\n",
    "for idx in range(1, no_pages+1):\n",
    "    # Load page\n",
    "    driver.get(season_url+str(idx))\n",
    "    # explicitly wait till page is loaded\n",
    "    wait.until(EC.visibility_of_element_located((By.ID, 'tournamentTable')))\n",
    "    # Process HTLM into data\n",
    "    soup = bs4.BeautifulSoup(driver.page_source)\n",
    "    _data += get_unique_href(soup, league, season)\n",
    "\n",
    "# create dataframe with unqiue URLS\n",
    "df_urls = pd.DataFrame(_data, columns=[\"League\", \"Season\", \"URL\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Analyze matches in more detail"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 244,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_team_names(soup):\n",
    "    \"\"\"\n",
    "    Input:\n",
    "        soup: BS4 soup element\n",
    "    \"\"\"\n",
    "    try:\n",
    "        names = soup.h1.text.split(\" - \")\n",
    "        return names[0], names[1]\n",
    "    except Exception as e:\n",
    "        print(e)\n",
    "        print(\"Team names not found\")\n",
    "        return np.nan, np.nan\n",
    "    \n",
    "            \n",
    "def load_page(driver, url):\n",
    "    \"\"\"\n",
    "    Return true if page was loaded correctly, else if error occured\n",
    "    \"\"\"\n",
    "    try:\n",
    "        driver.get(url)\n",
    "        return True\n",
    "    except Exception as e:\n",
    "        print(\"page not loaded\")\n",
    "        print(f\"{e}\")\n",
    "        return False\n",
    "    \n",
    "def get_match_date(soup):\n",
    "    \"\"\"\n",
    "    Return date as string\n",
    "    \"\"\"   \n",
    "    try:\n",
    "        match_date = soup.find(\"div\", {\"id\": \"col-left\"}).p.text\n",
    "        datetime_object = datetime.strptime(match_date, '%A, %d %b %Y, %H:%M')\n",
    "        return datetime_object\n",
    "    except:\n",
    "        return np.nan  \n",
    "    \n",
    "def get_opening_odds(driver):\n",
    "    \"\"\"\n",
    "    Return closing odds\n",
    "    \"\"\"\n",
    "    soup = bs4.BeautifulSoup(driver.page_source)\n",
    "    try:\n",
    "        _coef_open = soup.find(\"span\", {\"id\": \"tooltiptext\"}).contents[-2].text\n",
    "        return convert_2_float(_coef_open)\n",
    "    except:\n",
    "        return np.nan\n",
    "    \n",
    "def get_score(soup):\n",
    "    \"\"\"\n",
    "    Return\n",
    "    \"\"\"\n",
    "    element = soup.find(\"p\", {\"class\": \"result\"})\n",
    "    quater_scores = element.contents[-1].split(\",\")\n",
    "    if len(element.strong.text.split(\"OT\"))==1:\n",
    "        OT = False\n",
    "        home_s = convert_2_int(element.strong.text.split(\":\")[0])\n",
    "        away_s = convert_2_int(element.strong.text.split(\":\")[1])\n",
    "    else:\n",
    "        OT = True\n",
    "        score_string = element.strong.text.split(\"OT\")[0][:-1]\n",
    "        home_s = convert_2_int(score_string.split(\":\")[0])\n",
    "        away_s = convert_2_int(score_string.split(\":\")[1])\n",
    "        \n",
    "    # get quater scores    \n",
    "    Q1 = quater_scores[0][2:].split(\":\")\n",
    "    Q1_h = convert_2_int(Q1[0])\n",
    "    Q1_a = convert_2_int(Q1[1])\n",
    "    Q2 = quater_scores[1][1:].split(\":\")\n",
    "    Q2_h = convert_2_int(Q2[0])\n",
    "    Q2_a = convert_2_int(Q2[1])\n",
    "    Q3 = quater_scores[2][1:].split(\":\")\n",
    "    Q3_h = convert_2_int(Q3[0])\n",
    "    Q3_a = convert_2_int(Q3[1])\n",
    "    Q4 = quater_scores[3][1:-1].split(\":\")\n",
    "    Q4_h = convert_2_int(Q4[0])\n",
    "    Q4_a = convert_2_int(Q4[1])\n",
    "        \n",
    "    return [home_s, away_s, OT, Q1_h, Q1_a, Q2_h, Q2_a, Q3_h, Q3_a, Q4_h, Q4_a]\n",
    "    \n",
    "def get_h2h_coef(driver):\n",
    "    \"\"\"\n",
    "    Return list of list with \n",
    "    \"\"\"\n",
    "    main_table = driver.find_element_by_xpath(\"//table[@class='table-main detail-odds sortable']\")\n",
    "    main_table = main_table.find_element_by_tag_name('tbody')\n",
    "    _data = [np.nan]*12\n",
    "    for _ in main_table.find_elements_by_tag_name('tr'):\n",
    "        # filter out empty rows\n",
    "        row = _.find_elements_by_tag_name('td')\n",
    "        if len(row) == 5:\n",
    "            book_name = row[0].text[1:-2]\n",
    "            # exclude empty rows\n",
    "            if book_name == '':\n",
    "                continue\n",
    "            # remove new bookmaker tags\n",
    "            if book_name[-4:] == '\\nNEW':\n",
    "                book_name = book_name.replace('\\nNEW', '')\n",
    "\n",
    "            if book_name in [\"bet365\", \"Dafabet\", \"Pinnacle\"]:\n",
    "                # read different bookmaker prices\n",
    "\n",
    "                # H2H home coef.\n",
    "                _element = row[1]\n",
    "                _coef_close = convert_2_float(_element.text)\n",
    "                ActionChains(driver).move_to_element(_element).perform()\n",
    "                _coef_open = get_opening_odds(driver)\n",
    "                if book_name==\"bet365\":\n",
    "                    _data[0] = _coef_close\n",
    "                    _data[1] = _coef_open\n",
    "                elif book_name==\"Dafabet\":\n",
    "                    _data[4] = _coef_close\n",
    "                    _data[5] = _coef_open\n",
    "                else:\n",
    "                    _data[8] = _coef_close\n",
    "                    _data[9] = _coef_open\n",
    "\n",
    "                # H2H away coef.\n",
    "                _element = row[2]\n",
    "                _coef_close = convert_2_float(_element.text)\n",
    "                ActionChains(driver).move_to_element(_element).perform()\n",
    "                _coef_open = get_opening_odds(driver)\n",
    "                if book_name==\"bet365\":\n",
    "                    _data[2] = _coef_close\n",
    "                    _data[3] = _coef_open\n",
    "                elif book_name==\"Dafabet\":\n",
    "                    _data[6] = _coef_close\n",
    "                    _data[7] = _coef_open\n",
    "                else:\n",
    "                    _data[10] = _coef_close\n",
    "                    _data[11] = _coef_open\n",
    "    \n",
    "    return _data        \n",
    "\n",
    "def click_AH_OU_button(driver, wait, AH=True):\n",
    "    try:\n",
    "        if AH:\n",
    "            # click AH button\n",
    "            driver.find_element_by_xpath(\"//span[contains(text(), 'AH')]\").click()\n",
    "        else:\n",
    "            # click OU button\n",
    "            driver.find_element_by_xpath(\"//span[contains(text(), 'O/U')]\").click()\n",
    "        wait.until(EC.element_to_be_clickable((By.ID, 'odds-data-table')))\n",
    "    except Exception as e:\n",
    "        print(\"Button not found\")\n",
    "        print(e)\n",
    "        \n",
    "def click_xpath(driver, xpath):\n",
    "    \"\"\"\n",
    "    Tries to click on Xpath element\n",
    "    \"\"\"\n",
    "    try:\n",
    "        driver.find_element_by_xpath(xpath).click()\n",
    "    except Exception as e:\n",
    "        print(\"Error {} occured\".format(e))\n",
    "        \n",
    "def click_max_book_market(driver, soup, ah = True):\n",
    "    \"\"\"\n",
    "    Find and click on AH or OU market with highest number of bookmakers\n",
    "    \"\"\"\n",
    "    soup = bs4.BeautifulSoup(driver.page_source)\n",
    "    rows = soup.find(\"div\", {\"id\": \"odds-data-table\"}).findAll(\"div\", {\"class\": \"table-container\"})\n",
    "    \n",
    "    max_book_count = 0\n",
    "    max_type = np.nan\n",
    "    for row in rows:\n",
    "        if row.strong is not None:\n",
    "            if row.strong.text[:5] != \"Click\":\n",
    "                if convert_2_int(row.find(\"span\", {\"class\": \"odds-cnt\"}).text[1:-1]) > max_book_count:\n",
    "                    max_book_count = convert_2_int(row.find(\"span\", {\"class\": \"odds-cnt\"}).text[1:-1])\n",
    "                    if ah:\n",
    "                        max_type = row.strong.text[15:]\n",
    "                    else:\n",
    "                        max_type = row.strong.text[11:]\n",
    "\n",
    "    if ah:\n",
    "        _xpath = \"//*[contains(text(), 'Asian handicap \" + max_type + \"')]\"\n",
    "    else:\n",
    "        _xpath = \"//*[contains(text(), 'Over/Under \" + max_type + \"')]\"\n",
    "\n",
    "    click_xpath(driver, _xpath)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 287,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan]\n",
      "[163.5, 1.9, 2.0, 1.9, 2.0, nan, nan, nan, nan, nan, nan, nan, nan]\n",
      "[nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan]\n",
      "[171.5, 1.9, 2.0, 1.9, 2.0, nan, nan, nan, nan, nan, nan, nan, nan]\n",
      "Dafa\n",
      "[nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan]\n",
      "[173.5, nan, nan, nan, nan, 1.86, 1.94, 1.98, 2.06, nan, nan, nan, nan]\n",
      "[nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan]\n",
      "[155.5, 1.9, 2.0, 1.9, 2.0, nan, nan, nan, nan, nan, nan, nan, nan]\n",
      "[nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan]\n",
      "[165.0, 1.9, 2.0, 1.9, 2.0, nan, nan, nan, nan, nan, nan, nan, nan]\n",
      "[nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan]\n",
      "[167.5, 1.9, 2.0, 1.9, 2.0, nan, nan, nan, nan, nan, nan, nan, nan]\n",
      "[nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan]\n",
      "[160.5, 1.9, 2.0, 1.9, 2.0, nan, nan, nan, nan, nan, nan, nan, nan]\n",
      "Dafa\n",
      "[nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan]\n",
      "[150.0, nan, nan, nan, nan, 1.9, 1.98, 1.94, 2.02, nan, nan, nan, nan]\n",
      "Dafa\n",
      "[nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan]\n",
      "[170.5, nan, nan, nan, nan, 1.9, 1.98, 1.94, 2.02, nan, nan, nan, nan]\n",
      "Dafa\n",
      "[nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan]\n",
      "[166.5, nan, nan, nan, nan, 1.94, 2.02, 1.9, 1.98, nan, nan, nan, nan]\n",
      "Wall time: 2min 15s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "# temporary list to store data\n",
    "_data = list()\n",
    "failed_urls = list()\n",
    "\n",
    "for url in df_urls.URL.values[:10]:\n",
    "    if load_page(driver, url):\n",
    "        # wait till page is loaded\n",
    "        wait.until(EC.visibility_of_element_located((By.ID , \"odds-data-table\")))\n",
    "        # scroll down, so that all bookmakers are accecible\n",
    "        driver.execute_script(\"window.scrollTo(0, 320)\")\n",
    "        # get soup element\n",
    "        soup = bs4.BeautifulSoup(driver.page_source)\n",
    "        # read team names\n",
    "        home_n, away_n = get_team_names(soup)\n",
    "        # get match date\n",
    "        match_date = get_match_date(soup)\n",
    "        # get score\n",
    "        score = get_score(soup)\n",
    "        # get bookmaker prices\n",
    "        _coefs = get_h2h_coef(driver)\n",
    "        \n",
    "        # get Asian handicap info\n",
    "        # click AH button\n",
    "        click_AH_OU_button(driver, wait)\n",
    "        # click on max book AH market\n",
    "        click_max_book_market(driver, bs4.BeautifulSoup(driver.page_source))\n",
    "        \n",
    "        # get OU info\n",
    "        # click OU button\n",
    "        click_AH_OU_button(driver, wait, False)\n",
    "        # click on max book OU market\n",
    "        click_max_book_market(driver, bs4.BeautifulSoup(driver.page_source), False)\n",
    "        \n",
    "        \n",
    "        # add data\n",
    "        _data.append([match_date, home_n, away_n, url]+score+_coefs)\n",
    "    else:\n",
    "        failed_urls.append([url])\n",
    "        \n",
    "# create DataFrame\n",
    "df_events = pd.DataFrame(_data, columns=[\"Date\", \"Home_n\", \"Away_n\", \"URL\", \"Home_score\", \"Away_score\", \"OT\",\n",
    "                                         \"Q1_home\", \"Q1_away\", \"Q2_home\", \"Q2_away\", \"Q3_Home\", \"Q3_away\",\n",
    "                                         \"Q4_home\", \"Q4_away\",\n",
    "                                         \"H2H_home_bet365_close\", \"H2H_home_bet365_open\",\n",
    "                                         \"H2H_away_bet365_close\", \"H2H_away_bet365_open\",\n",
    "                                         \"H2H_home_Dafa_close\", \"H2H_home_Dafa_open\",\n",
    "                                         \"H2H_away_Dafa_close\", \"H2H_away_Dafa_open\",\n",
    "                                         \"H2H_home_Pinnacle_close\", \"H2H_home_Pinnacle_open\",\n",
    "                                         \"H2H_away_Pinnacle_close\", \"H2H_away_Pinnacle_open\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 189,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Date</th>\n",
       "      <th>Home_n</th>\n",
       "      <th>Away_n</th>\n",
       "      <th>URL</th>\n",
       "      <th>Home_score</th>\n",
       "      <th>Away_score</th>\n",
       "      <th>OT</th>\n",
       "      <th>Q1_home</th>\n",
       "      <th>Q1_away</th>\n",
       "      <th>Q2_home</th>\n",
       "      <th>...</th>\n",
       "      <th>H2H_away_bet365_close</th>\n",
       "      <th>H2H_away_bet365_open</th>\n",
       "      <th>H2H_home_Dafa_close</th>\n",
       "      <th>H2H_home_Dafa_open</th>\n",
       "      <th>H2H_away_Dafa_close</th>\n",
       "      <th>H2H_away_Dafa_open</th>\n",
       "      <th>H2H_home_Pinnacle_close</th>\n",
       "      <th>H2H_home_Pinnacle_open</th>\n",
       "      <th>H2H_away_Pinnacle_close</th>\n",
       "      <th>H2H_away_Pinnacle_open</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2018-05-20 21:00:00</td>\n",
       "      <td>Real Madrid</td>\n",
       "      <td>Fenerbahce</td>\n",
       "      <td>https://www.oddsportal.com/basketball/europe/e...</td>\n",
       "      <td>85</td>\n",
       "      <td>80</td>\n",
       "      <td>False</td>\n",
       "      <td>21</td>\n",
       "      <td>17</td>\n",
       "      <td>17</td>\n",
       "      <td>...</td>\n",
       "      <td>2.00</td>\n",
       "      <td>2.00</td>\n",
       "      <td>1.88</td>\n",
       "      <td>1.92</td>\n",
       "      <td>1.98</td>\n",
       "      <td>1.92</td>\n",
       "      <td>1.94</td>\n",
       "      <td>1.95</td>\n",
       "      <td>1.96</td>\n",
       "      <td>1.95</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2018-05-20 18:00:00</td>\n",
       "      <td>CSKA Moscow</td>\n",
       "      <td>Zalgiris Kaunas</td>\n",
       "      <td>https://www.oddsportal.com/basketball/europe/e...</td>\n",
       "      <td>77</td>\n",
       "      <td>79</td>\n",
       "      <td>False</td>\n",
       "      <td>19</td>\n",
       "      <td>22</td>\n",
       "      <td>16</td>\n",
       "      <td>...</td>\n",
       "      <td>3.15</td>\n",
       "      <td>3.50</td>\n",
       "      <td>1.33</td>\n",
       "      <td>1.40</td>\n",
       "      <td>3.43</td>\n",
       "      <td>3.04</td>\n",
       "      <td>1.42</td>\n",
       "      <td>1.40</td>\n",
       "      <td>3.14</td>\n",
       "      <td>3.22</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2018-05-18 22:00:00</td>\n",
       "      <td>CSKA Moscow</td>\n",
       "      <td>Real Madrid</td>\n",
       "      <td>https://www.oddsportal.com/basketball/europe/e...</td>\n",
       "      <td>83</td>\n",
       "      <td>92</td>\n",
       "      <td>False</td>\n",
       "      <td>30</td>\n",
       "      <td>20</td>\n",
       "      <td>16</td>\n",
       "      <td>...</td>\n",
       "      <td>2.55</td>\n",
       "      <td>2.55</td>\n",
       "      <td>1.63</td>\n",
       "      <td>1.60</td>\n",
       "      <td>2.36</td>\n",
       "      <td>2.38</td>\n",
       "      <td>1.63</td>\n",
       "      <td>1.68</td>\n",
       "      <td>2.44</td>\n",
       "      <td>2.32</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2018-05-18 19:00:00</td>\n",
       "      <td>Fenerbahce</td>\n",
       "      <td>Zalgiris Kaunas</td>\n",
       "      <td>https://www.oddsportal.com/basketball/europe/e...</td>\n",
       "      <td>76</td>\n",
       "      <td>67</td>\n",
       "      <td>False</td>\n",
       "      <td>19</td>\n",
       "      <td>13</td>\n",
       "      <td>20</td>\n",
       "      <td>...</td>\n",
       "      <td>3.00</td>\n",
       "      <td>3.30</td>\n",
       "      <td>1.42</td>\n",
       "      <td>1.38</td>\n",
       "      <td>3.00</td>\n",
       "      <td>3.12</td>\n",
       "      <td>1.43</td>\n",
       "      <td>1.38</td>\n",
       "      <td>3.05</td>\n",
       "      <td>3.34</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2018-04-27 22:00:00</td>\n",
       "      <td>Real Madrid</td>\n",
       "      <td>Panathinaikos</td>\n",
       "      <td>https://www.oddsportal.com/basketball/europe/e...</td>\n",
       "      <td>89</td>\n",
       "      <td>82</td>\n",
       "      <td>False</td>\n",
       "      <td>19</td>\n",
       "      <td>14</td>\n",
       "      <td>32</td>\n",
       "      <td>...</td>\n",
       "      <td>3.30</td>\n",
       "      <td>3.50</td>\n",
       "      <td>1.35</td>\n",
       "      <td>1.38</td>\n",
       "      <td>3.32</td>\n",
       "      <td>3.12</td>\n",
       "      <td>1.40</td>\n",
       "      <td>1.37</td>\n",
       "      <td>3.21</td>\n",
       "      <td>3.40</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>2018-04-27 20:00:00</td>\n",
       "      <td>Khimki M.</td>\n",
       "      <td>CSKA Moscow</td>\n",
       "      <td>https://www.oddsportal.com/basketball/europe/e...</td>\n",
       "      <td>88</td>\n",
       "      <td>89</td>\n",
       "      <td>False</td>\n",
       "      <td>25</td>\n",
       "      <td>32</td>\n",
       "      <td>19</td>\n",
       "      <td>...</td>\n",
       "      <td>1.52</td>\n",
       "      <td>1.47</td>\n",
       "      <td>2.53</td>\n",
       "      <td>2.42</td>\n",
       "      <td>1.55</td>\n",
       "      <td>1.58</td>\n",
       "      <td>2.60</td>\n",
       "      <td>2.59</td>\n",
       "      <td>1.56</td>\n",
       "      <td>1.56</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>2018-04-26 22:00:00</td>\n",
       "      <td>Baskonia</td>\n",
       "      <td>Fenerbahce</td>\n",
       "      <td>https://www.oddsportal.com/basketball/europe/e...</td>\n",
       "      <td>83</td>\n",
       "      <td>92</td>\n",
       "      <td>False</td>\n",
       "      <td>19</td>\n",
       "      <td>25</td>\n",
       "      <td>13</td>\n",
       "      <td>...</td>\n",
       "      <td>1.83</td>\n",
       "      <td>2.10</td>\n",
       "      <td>2.12</td>\n",
       "      <td>1.86</td>\n",
       "      <td>1.76</td>\n",
       "      <td>1.98</td>\n",
       "      <td>2.00</td>\n",
       "      <td>1.85</td>\n",
       "      <td>1.91</td>\n",
       "      <td>2.06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>2018-04-26 20:00:00</td>\n",
       "      <td>Zalgiris Kaunas</td>\n",
       "      <td>Olympiakos</td>\n",
       "      <td>https://www.oddsportal.com/basketball/europe/e...</td>\n",
       "      <td>101</td>\n",
       "      <td>91</td>\n",
       "      <td>False</td>\n",
       "      <td>23</td>\n",
       "      <td>22</td>\n",
       "      <td>28</td>\n",
       "      <td>...</td>\n",
       "      <td>2.67</td>\n",
       "      <td>2.67</td>\n",
       "      <td>1.46</td>\n",
       "      <td>1.55</td>\n",
       "      <td>2.81</td>\n",
       "      <td>2.49</td>\n",
       "      <td>1.55</td>\n",
       "      <td>1.55</td>\n",
       "      <td>2.65</td>\n",
       "      <td>2.65</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>2018-04-25 20:00:00</td>\n",
       "      <td>Khimki M.</td>\n",
       "      <td>CSKA Moscow</td>\n",
       "      <td>https://www.oddsportal.com/basketball/europe/e...</td>\n",
       "      <td>79</td>\n",
       "      <td>73</td>\n",
       "      <td>False</td>\n",
       "      <td>17</td>\n",
       "      <td>15</td>\n",
       "      <td>27</td>\n",
       "      <td>...</td>\n",
       "      <td>1.57</td>\n",
       "      <td>1.52</td>\n",
       "      <td>2.49</td>\n",
       "      <td>2.63</td>\n",
       "      <td>1.57</td>\n",
       "      <td>1.50</td>\n",
       "      <td>2.45</td>\n",
       "      <td>2.76</td>\n",
       "      <td>1.62</td>\n",
       "      <td>1.51</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>2018-04-25 19:45:00</td>\n",
       "      <td>Real Madrid</td>\n",
       "      <td>Panathinaikos</td>\n",
       "      <td>https://www.oddsportal.com/basketball/europe/e...</td>\n",
       "      <td>81</td>\n",
       "      <td>74</td>\n",
       "      <td>False</td>\n",
       "      <td>17</td>\n",
       "      <td>17</td>\n",
       "      <td>23</td>\n",
       "      <td>...</td>\n",
       "      <td>3.30</td>\n",
       "      <td>3.50</td>\n",
       "      <td>1.34</td>\n",
       "      <td>1.34</td>\n",
       "      <td>3.38</td>\n",
       "      <td>3.38</td>\n",
       "      <td>1.37</td>\n",
       "      <td>1.30</td>\n",
       "      <td>3.39</td>\n",
       "      <td>3.89</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>10 rows Ã— 27 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                 Date           Home_n           Away_n  \\\n",
       "0 2018-05-20 21:00:00      Real Madrid       Fenerbahce   \n",
       "1 2018-05-20 18:00:00      CSKA Moscow  Zalgiris Kaunas   \n",
       "2 2018-05-18 22:00:00      CSKA Moscow      Real Madrid   \n",
       "3 2018-05-18 19:00:00       Fenerbahce  Zalgiris Kaunas   \n",
       "4 2018-04-27 22:00:00      Real Madrid    Panathinaikos   \n",
       "5 2018-04-27 20:00:00        Khimki M.      CSKA Moscow   \n",
       "6 2018-04-26 22:00:00         Baskonia       Fenerbahce   \n",
       "7 2018-04-26 20:00:00  Zalgiris Kaunas       Olympiakos   \n",
       "8 2018-04-25 20:00:00        Khimki M.      CSKA Moscow   \n",
       "9 2018-04-25 19:45:00      Real Madrid    Panathinaikos   \n",
       "\n",
       "                                                 URL  Home_score  Away_score  \\\n",
       "0  https://www.oddsportal.com/basketball/europe/e...          85          80   \n",
       "1  https://www.oddsportal.com/basketball/europe/e...          77          79   \n",
       "2  https://www.oddsportal.com/basketball/europe/e...          83          92   \n",
       "3  https://www.oddsportal.com/basketball/europe/e...          76          67   \n",
       "4  https://www.oddsportal.com/basketball/europe/e...          89          82   \n",
       "5  https://www.oddsportal.com/basketball/europe/e...          88          89   \n",
       "6  https://www.oddsportal.com/basketball/europe/e...          83          92   \n",
       "7  https://www.oddsportal.com/basketball/europe/e...         101          91   \n",
       "8  https://www.oddsportal.com/basketball/europe/e...          79          73   \n",
       "9  https://www.oddsportal.com/basketball/europe/e...          81          74   \n",
       "\n",
       "      OT  Q1_home  Q1_away  Q2_home           ...            \\\n",
       "0  False       21       17       17           ...             \n",
       "1  False       19       22       16           ...             \n",
       "2  False       30       20       16           ...             \n",
       "3  False       19       13       20           ...             \n",
       "4  False       19       14       32           ...             \n",
       "5  False       25       32       19           ...             \n",
       "6  False       19       25       13           ...             \n",
       "7  False       23       22       28           ...             \n",
       "8  False       17       15       27           ...             \n",
       "9  False       17       17       23           ...             \n",
       "\n",
       "   H2H_away_bet365_close  H2H_away_bet365_open  H2H_home_Dafa_close  \\\n",
       "0                   2.00                  2.00                 1.88   \n",
       "1                   3.15                  3.50                 1.33   \n",
       "2                   2.55                  2.55                 1.63   \n",
       "3                   3.00                  3.30                 1.42   \n",
       "4                   3.30                  3.50                 1.35   \n",
       "5                   1.52                  1.47                 2.53   \n",
       "6                   1.83                  2.10                 2.12   \n",
       "7                   2.67                  2.67                 1.46   \n",
       "8                   1.57                  1.52                 2.49   \n",
       "9                   3.30                  3.50                 1.34   \n",
       "\n",
       "   H2H_home_Dafa_open  H2H_away_Dafa_close  H2H_away_Dafa_open  \\\n",
       "0                1.92                 1.98                1.92   \n",
       "1                1.40                 3.43                3.04   \n",
       "2                1.60                 2.36                2.38   \n",
       "3                1.38                 3.00                3.12   \n",
       "4                1.38                 3.32                3.12   \n",
       "5                2.42                 1.55                1.58   \n",
       "6                1.86                 1.76                1.98   \n",
       "7                1.55                 2.81                2.49   \n",
       "8                2.63                 1.57                1.50   \n",
       "9                1.34                 3.38                3.38   \n",
       "\n",
       "   H2H_home_Pinnacle_close  H2H_home_Pinnacle_open  H2H_away_Pinnacle_close  \\\n",
       "0                     1.94                    1.95                     1.96   \n",
       "1                     1.42                    1.40                     3.14   \n",
       "2                     1.63                    1.68                     2.44   \n",
       "3                     1.43                    1.38                     3.05   \n",
       "4                     1.40                    1.37                     3.21   \n",
       "5                     2.60                    2.59                     1.56   \n",
       "6                     2.00                    1.85                     1.91   \n",
       "7                     1.55                    1.55                     2.65   \n",
       "8                     2.45                    2.76                     1.62   \n",
       "9                     1.37                    1.30                     3.39   \n",
       "\n",
       "   H2H_away_Pinnacle_open  \n",
       "0                    1.95  \n",
       "1                    3.22  \n",
       "2                    2.32  \n",
       "3                    3.34  \n",
       "4                    3.40  \n",
       "5                    1.56  \n",
       "6                    2.06  \n",
       "7                    2.65  \n",
       "8                    1.51  \n",
       "9                    3.89  \n",
       "\n",
       "[10 rows x 27 columns]"
      ]
     },
     "execution_count": 189,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_events"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 284,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_ou_prices(soup):\n",
    "    \"\"\"\n",
    "    Input:\n",
    "        soup: bs4 soup element\n",
    "    Output:\n",
    "        list of lists\n",
    "    \"\"\"\n",
    "    rows = soup.find(\"div\", {\"id\": \"odds-data-table\"}).findAll(\"div\", {\"class\": \"table-container\"})\n",
    "    _data_list = _data_list = [np.nan]*13\n",
    "    for row in rows:\n",
    "        avg_p = row.find(\"tr\", {\"class\": \"aver\"})\n",
    "        max_p = row.find(\"tr\", {\"class\": \"highest\"})\n",
    "        if avg_p is not None and max_p is not None:\n",
    "            bet_type = convert_2_float(row.contents[0].strong.text[12:-1])\n",
    "            if row.find(\"a\", string=\"bet365\") is not None:\n",
    "                _prices = row.find(\"a\", string=\"bet365\").parent.parent.parent.findAll(\"td\")\n",
    "                _o = convert_2_float(_prices[2].text)\n",
    "                _u = convert_2_float(_prices[3].text)\n",
    "                _o_prop = round(((_u + _o) / _u), 2) \n",
    "                _u_prop = round(((_u + _o) / _o), 2)\n",
    "                _data_list[0] = bet_type\n",
    "                _data_list[1] = _o\n",
    "                _data_list[2] = _o_prop\n",
    "                _data_list[3] = _u\n",
    "                _data_list[4] = _u_prop\n",
    "            elif row.find(\"a\", string=\"Dafabet\") is not None:\n",
    "                _prices = row.find(\"a\", string=\"Dafabet\").parent.parent.parent.findAll(\"td\")\n",
    "                _o = convert_2_float(_prices[2].text)\n",
    "                _u = convert_2_float(_prices[3].text)\n",
    "                _o_prop = round(((_u + _o) / _u), 2) \n",
    "                _u_prop = round(((_u + _o) / _o), 2)\n",
    "                _data_list[0] = bet_type\n",
    "                _data_list[5] = _o\n",
    "                _data_list[6] = _o_prop\n",
    "                _data_list[7] = _u\n",
    "                _data_list[8] = _u_prop\n",
    "            elif row.find(\"a\", string=\"Pinnacle\") is not None:\n",
    "                _prices = row.find(\"a\", string=\"Pinnacle\").parent.parent.parent.findAll(\"td\")\n",
    "                _o = convert_2_float(_prices[2].text)\n",
    "                _u = convert_2_float(_prices[3].text)\n",
    "                _o_prop = round(((_u + _o) / _u), 2) \n",
    "                _u_prop = round(((_u + _o) / _o), 2)\n",
    "                _data_list[0] = bet_type\n",
    "                _data_list[9] = _o\n",
    "                _data_list[10] = _o_prop\n",
    "                _data_list[11] = _u\n",
    "                _data_list[12] = _u_prop\n",
    "\n",
    "    return _data_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 286,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dafa\n",
      "[nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[166.5, nan, nan, nan, nan, 1.94, 2.02, 1.9, 1.98, nan, nan, nan, nan]"
      ]
     },
     "execution_count": 286,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "soup = bs4.BeautifulSoup(driver.page_source)\n",
    "get_ou_prices(bs4.BeautifulSoup(driver.page_source))\n",
    "                \n",
    "                \n",
    "# table = soup.find(\"div\", {\"id\": \"odds-data-table\"})\n",
    "# table = table.findAll(\"div\", {\"class\": \"table-container\"})\n",
    "# for row in table:\n",
    "#     if row.text != \"BETTING EXCHANGES\":\n",
    "#         if ah:\n",
    "#             bet_type = row.strong.text[15:]\n",
    "#         else:\n",
    "#             bet_type = row.strong.text[11:]\n",
    "#         odd_count = int(row.find(\"span\", {\"class\": \"odds-cnt\"}).text[1:-1])\n",
    "#         print(bet_type)\n",
    "#         print(odd_count)\n",
    "#         if odd_count >= 10:\n",
    "#             if ah:\n",
    "#                 _xpath = \"//*[contains(text(), 'Asian handicap \" + bet_type + \"')]\"\n",
    "#             else:\n",
    "#                 _xpath = \"//*[contains(text(), 'Over/Under \" + bet_type + \"')]\"\n",
    "#             self.click_xpath(_xpath)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 254,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan]"
      ]
     },
     "execution_count": 254,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "_data_list = [np.nan]*13\n",
    "_data_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 190,
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    # click AH button\n",
    "    driver.find_element_by_xpath(\"//span[contains(text(), 'AH')]\").click()\n",
    "    wait.until(EC.element_to_be_clickable((By.ID, 'odds-data-table')))\n",
    "#     # get soup\n",
    "#     soup = bs4.BeautifulSoup(driver.page_source)\n",
    "#     ah_prices = get_ah_ou_coef(soup)\n",
    "except Exception as e:\n",
    "    print(e)\n",
    "    print(\"AH prices not read\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 191,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "        \n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 192,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 185,
   "metadata": {},
   "outputs": [],
   "source": [
    "soup = bs4.BeautifulSoup(driver.page_source)\n",
    "element = soup.find(\"p\", {\"class\": \"result\"})\n",
    "quater_scores = element.contents[-1].split(\",\")\n",
    "if len(element.strong.text.split(\"OT\"))==1:\n",
    "    OT = False\n",
    "    home_s = convert_2_int(element.strong.text.split(\":\")[0])\n",
    "    away_s = convert_2_int(element.strong.text.split(\":\")[1])\n",
    "else:\n",
    "    OT = True\n",
    "    score_string = element.strong.text.split(\"OT\")[0][:-1]\n",
    "    home_s = convert_2_int(score_string.split(\":\")[0])\n",
    "    away_s = convert_2_int(score_string.split(\":\")[1])\n",
    "    \n",
    "Q1 = quater_scores[0][2:].split(\":\")\n",
    "Q1_h = convert_2_int(Q1[0])\n",
    "Q1_a = convert_2_int(Q1[1])\n",
    "Q2 = quater_scores[1][1:].split(\":\")\n",
    "Q2_h = convert_2_int(Q2[0])\n",
    "Q2_a = convert_2_int(Q2[1])\n",
    "Q3 = quater_scores[2][1:].split(\":\")\n",
    "Q3_h = convert_2_int(Q3[0])\n",
    "Q3_a = convert_2_int(Q3[1])\n",
    "Q4 = quater_scores[3][1:-1].split(\":\")\n",
    "Q4_h = convert_2_int(Q4[0])\n",
    "Q4_a = convert_2_int(Q4[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 186,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['24', '21']"
      ]
     },
     "execution_count": 186,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Q4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "81"
      ]
     },
     "execution_count": 117,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "home_s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "test = [np.nan, np.nan, np.nan, np.nan, np.nan, np.nan]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[1, nan, nan, nan, nan, nan]"
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test[0] = 1\n",
    "test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n",
      "2\n"
     ]
    }
   ],
   "source": [
    "for e in range(1, 3):\n",
    "    print(e)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df_events"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_example['Time'] = pd.to_datetime(df_example['Time'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Wednesday, 25 Apr  2018, 19:45'"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "match_date"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "datetime.datetime(2018, 4, 25, 19, 45)"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Wednesday, 25 Apr  2018, 19:45'"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_match_date(bs4.BeautifulSoup(driver.page_source))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "wait = WebDriverWait(driver, 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_ah_ou_coef(soup):\n",
    "    \"\"\"\n",
    "    Returns asian handicap coefficient or under/over totals, which were offered by largest number of book makers\n",
    "    Same logic applies for both type pages\n",
    "    input:\n",
    "        market_type: boolean, tells how to read asian handicap or over/under totals\n",
    "        soup: bs4.BeautifulSoup element (HTML source code parced with selenium webdriver)\n",
    "    output:\n",
    "        list: [asian handicap, home coef., away coef.]\n",
    "        or\n",
    "        list: [asian handicap, home coef., away coef.]\n",
    "    \"\"\"\n",
    "    table = soup.find(\"div\", {\"id\": \"odds-data-table\"})\n",
    "    table = table.findAll(\"div\", {\"class\": \"table-container\"})\n",
    "    max_book_count = 0\n",
    "    max_ah = np.nan\n",
    "    for row in table:\n",
    "        if row.text != \"BETTING EXCHANGES\":\n",
    "            odd_count = int(row.find(\"span\", {\"class\":\"odds-cnt\"}).text[1:-1])\n",
    "            if odd_count > max_book_count:\n",
    "                max_book_count = odd_count\n",
    "                bet_type = row.strong.text\n",
    "                price_1 = convert_2_float(row.findAll('span')[1].text)\n",
    "                price_2 = convert_2_float(row.findAll('span')[2].text)\n",
    "    return [bet_type, price_1, price_2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "_league = \"NBA\"\n",
    "_season = \"2018/2019\"\n",
    "filename = _league + \"_\" + _season.replace(\"/\",\"_\") + \".csv\"\n",
    "cond_1 = df_1.League == _league\n",
    "cond_2 = df_1.Season == _season\n",
    "df_c = df_1[cond_1 & cond_2]\n",
    "df_c.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Read NBA or Euro League detailed stats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "wait = WebDriverWait(driver, 20)\n",
    "all_data = list()\n",
    "i = 0\n",
    "for url in df_c.URL.values:\n",
    "    try:\n",
    "        driver.get(url)\n",
    "    except Exception as e:\n",
    "        print(\"page not loaded\")\n",
    "    ah_prices = [np.nan, np.nan, np.nan]\n",
    "    # get soup\n",
    "    soup = bs4.BeautifulSoup(driver.page_source)\n",
    "    # get team names\n",
    "    try:\n",
    "        names = soup.h1.text.split(\" - \")\n",
    "        name_h = names[0]\n",
    "        name_a = names[1]\n",
    "    except Exception as e:\n",
    "        name_h = np.nan\n",
    "        name_a = np.nan\n",
    "        print(e)\n",
    "        print(\"Team names not found\")\n",
    "    # get match date\n",
    "    try:\n",
    "        match_date = soup.find(\"div\", {\"id\": \"col-content\"}).p.text\n",
    "    except:\n",
    "        match_date = np.nan    \n",
    "    try:\n",
    "        # click AH button\n",
    "        driver.find_element_by_xpath(\"//span[contains(text(), 'AH')]\").click()\n",
    "        wait.until(EC.element_to_be_clickable((By.ID, 'odds-data-table')))\n",
    "        # get soup\n",
    "        soup = bs4.BeautifulSoup(driver.page_source)\n",
    "        ah_prices = get_ah_ou_coef(soup)\n",
    "    except Exception as e:\n",
    "        print(e)\n",
    "        print(\"AH prices not read\")  \n",
    "    ou_prices = [np.nan, np.nan, np.nan]\n",
    "    try:\n",
    "        # click OU button\n",
    "        driver.find_element_by_xpath(\"//span[contains(text(), 'O/U')]\").click()\n",
    "        wait.until(EC.element_to_be_clickable((By.ID, 'odds-data-table')))\n",
    "        # get soup\n",
    "        soup = bs4.BeautifulSoup(driver.page_source)\n",
    "        ou_prices = get_ah_ou_coef(soup)\n",
    "    except Exception as e:\n",
    "        print(e)\n",
    "        print(\"OU prices not read\")\n",
    "    # add new data\n",
    "    all_data.append(ah_prices + ou_prices + [name_h, name_a, match_date, url])\n",
    "    # save temporary data:\n",
    "    if i%100==0:\n",
    "        # make temporal save in case webdriver crashes, loss of internet connection, ect.\n",
    "        filename = _league + \"_\" + _season.replace(\"/\",\"_\") + \"_\" + str(i-100) + \"_\" + str(i)+ \".csv\"\n",
    "        df_2 = pd.DataFrame(all_data, columns=[\"AH\", \"AH_Home\", \"AH_Away\",\n",
    "                                       \"OU\", \"Over\", \"Under\",\n",
    "                                       \"Home_name\", \"Away_name\", \"Date\", \"URL\"])\n",
    "        df_2.to_csv(filename)\n",
    "    i+=1\n",
    "filename = _league + \"_\" + _season.replace(\"/\",\"_\") + \"_\" + str(i)+ \".csv\"\n",
    "df_2 = pd.DataFrame(all_data, columns=[\"AH\", \"AH_Home\", \"AH_Away\",\n",
    "                                       \"OU\", \"Over\", \"Under\",\n",
    "                                       \"Home_name\", \"Away_name\", \"Date\", \"URL\"])\n",
    "df_2.to_csv(filename)\n",
    "df_2.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Turn off webdriver"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 288,
   "metadata": {},
   "outputs": [],
   "source": [
    "driver.quit()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# OLD code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "season_dict = {\n",
    "    \"NBA_2018/2019\": (\"https://www.oddsportal.com/basketball/usa/nba/results//#/page/\", 8)\n",
    "    \"NBA_2017/2018\": (\"https://www.oddsportal.com/basketball/usa/nba-2017-2018/results/#/page/\", 28),\n",
    "    \"NBA_2016/2017\": (\"https://www.oddsportal.com/basketball/usa/nba-2016-2017/results/#/page/\", 29),\n",
    "    \"NBA_2015/2016\": (\"https://www.oddsportal.com/basketball/usa/nba-2015-2016/results/#/page/\", 29),\n",
    "    \"NBA_2014/2015\": (\"https://www.oddsportal.com/basketball/usa/nba-2014-2015/results/#/page/\", 29),\n",
    "    \"NBA_2013/2014\": (\"https://www.oddsportal.com/basketball/usa/nba-2013-2014/results/#/page/\", 29),\n",
    "    \"EURO_2017/2018\": (\"https://www.oddsportal.com/basketball/europe/euroleague-2017-2018/results/#/page/\", 6),\n",
    "    \"EURO_2016/2017\": (\"https://www.oddsportal.com/basketball/europe/euroleague-2016-2017/results/#/page/\", 6),\n",
    "    \"EURO_2015/2016\": (\"https://www.oddsportal.com/basketball/europe/euroleague-2015-2016/results/#/page/\", 5),\n",
    "    \"EURO_2014/2015\": (\"https://www.oddsportal.com/basketball/europe/euroleague-2014-2015/results/#/page/\", 6),\n",
    "    \"EURO_2013/2014\": (\"https://www.oddsportal.com/basketball/europe/euroleague-2013-2014/results/#/page/\", 6)\n",
    "}\n",
    "\n",
    "all_data = list()\n",
    "for key in season_dict.keys():\n",
    "    # Load main url page\n",
    "    url = season_dict[key][0]\n",
    "    # Extract league and season from key string\n",
    "    league = key.split(\"_\")[0]\n",
    "    season = key.split(\"_\")[1]\n",
    "    # Iterate over all pages for particular season\n",
    "    for idx in range(1, season_dict[key][1]+1):\n",
    "        # Load page\n",
    "        driver.get(url+str(idx))\n",
    "        # quick and dirty fix, implicit wait for 1.5 sec,  so that page is really loaded\n",
    "        time.sleep(5)\n",
    "        # Process HTLM into data\n",
    "        soup = bs4.BeautifulSoup(driver.page_source)\n",
    "        all_data += process_soup(soup, league, season)\n",
    "        \n",
    "df_1 = pd.DataFrame(all_data, columns=[\"League\", \"Season\", \"Home_score\", \"Away_score\",\n",
    "                                       \"Win\", \"OT\", \"Home_p\", \"Away_p\", \"URL\"])\n",
    "df_1.to_csv(\"basketball_scores.csv\")\n",
    "df_1.head()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
